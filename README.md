# Healthcare Insurance ğŸš€

## Overview  
This project is designed to build an end-to-end **data pipeline** for processing healthcare-related data, including **patients, doctors departments, insurance claims, transactions, CPT codes, ICD codes, and NPI codes**. The project follows a **Medallion Architecture (Bronze, Silver, Gold)** using **Azure Data Factory, Azure Databricks, and ADLS** for efficient data processing, transformation, and analytics.  

## Project Architecture  
The solution follows the **Medallion Architecture**, which consists of three layers:  

- **Bronze Layer**: Raw data ingestion from multiple sources.  
- **Silver Layer**: Data cleansing, transformations, and standardization.  
- **Gold Layer**: Aggregated and optimized data for analytics and reporting.  

### Data Sources  
- **Azure SQL Database / SQL Server** (Extracted via ADF)  
- **APIs** (ICD, NPI extracted via Databricks)  
- **Flat files (CSV, JSON, Parquet)** in **Azure Data Lake Storage (ADLS)**  

---

## Technologies Used ğŸ› ï¸  
- **Azure Data Factory (ADF)** â€“ For orchestrating data pipelines.  
- **Azure Data Lake Storage (ADLS Gen2)** â€“ For data storage.  
- **Azure Databricks (Spark, PySpark)** â€“ For data processing & transformations.  
- **Azure Key Vault** â€“ For securing sensitive credentials.  
- **Delta Lake** â€“ For handling large-scale data transformations.  
- **GitHub** â€“ For version control and CI/CD integration.  

---

## Project Structure ğŸ—ï¸  

```plaintext
ğŸ“‚ healthcare_insurance/
â”‚â”€â”€ ğŸ“‚ databricks_extracting_APIs/  # API extractions for ICD, NPI
â”‚â”€â”€ ğŸ“‚ databricks_gold_layer/       # Gold layer transformations (Facts & Dimensions)
â”‚â”€â”€ ğŸ“‚ databricks_setup/            # Setup files (Mounting, Audit, Catalog creation)
â”‚â”€â”€ ğŸ“‚ databricks_silver_layer/     # Silver layer transformations
â”‚â”€â”€ ğŸ“‚ dataset/                     # Sample datasets
â”‚â”€â”€ ğŸ“‚ factory/                      # ADF Factory settings
â”‚â”€â”€ ğŸ“‚ linkedService/                # ADF Linked Services
â”‚â”€â”€ ğŸ“‚ pipeline/                     # ADF Pipelines
â”‚â”€â”€ ğŸ“œ Architecture/                 # Project Architecture
â”‚â”€â”€ ğŸ“œ README.md                     # Project Documentation
â”‚â”€â”€ ğŸ“œ publish_config.json            # ADF Deployment Config
```

## Azure Data Factory (ADF) Implementation  
ADF is used to extract data **only from Azure SQL Database** and move it to the **Bronze layer** in ADLS.  

### Key ADF Activities Used:  
- âœ… **Lookup** â€“ To check configuration files for dynamic processing.  
- âœ… **ForEach** â€“ To iterate over multiple tables dynamically.  
- âœ… **If Condition** â€“ To control flow based on conditions.  
- âœ… **Copy Activity** â€“ To move data from source to destination.  
- âœ… **Execute Pipeline** â€“ To modularize pipelines.  
- âœ… **Databricks Notebook Activity** â€“ To trigger transformations in Databricks.  

## Azure Databricks Implementation  
Databricks is used for **data extraction, transformation, and loading (ETL) into Silver and Gold layers**.  

### Folders & Their Purpose:  
1ï¸âƒ£ **Setup**: Contains initialization scripts for **mounting ADLS, creating catalogs, and audit tables**.  
2ï¸âƒ£ **API Extraction**: Extracts **ICD, NPI** codes from external APIs. (CPT codes are directly available in ADLS.)  
3ï¸âƒ£ **Silver Layer**: Transforms **raw Bronze data** by removing duplicates, handling missing values, and standardizing formats.  
4ï¸âƒ£ **Gold Layer**: Builds **Facts & Dimensions** for analytical use cases.  

---

## Security Measures ğŸ”’  
- **Azure Key Vault**: Stores secrets such as API keys, database credentials, and storage access keys securely.  
- **Role-Based Access Control (RBAC)**: Ensures **least privilege** access to data.  

---

## ğŸ“¬ Contact
For any questions or support, reach out to me at **[vignanpatchigolla5@gmail.com]**.

## Setup & Deployment ğŸš€  

### 1ï¸âƒ£ Clone the Repository  
```sh
git clone https://github.com/VignanPatchigolla/insurances_healthcare.git
cd insurances_healthcare
